{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "\n",
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train['TARGET'].values\n",
    "X_train = df_train.drop(['ID','TARGET'], axis=1).values\n",
    "\n",
    "id_test = df_test['ID']\n",
    "X_test = df_test.drop(['ID'], axis=1).values\n",
    "\n",
    "# length of dataset\n",
    "len_train = len(X_train)\n",
    "len_test  = len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fit, X_eval, y_fit, y_eval= train_test_split(X_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC: 5 0.853657098301\n",
      "Overall AUC: 10 0.862657701468\n",
      "Overall AUC: 15 0.915623803163\n",
      "Overall AUC: 20 0.912583061469\n",
      "Overall AUC: 25 0.941139014915\n",
      "Overall AUC: 30 0.9375\n",
      "Overall AUC: 35 0.942727997966\n",
      "Overall AUC: 40 0.939572902599\n",
      "Overall AUC: 45 0.949106800904\n",
      "Overall AUC: 50 0.950166122938\n",
      "Overall AUC: 55 0.955416991638\n",
      "Overall AUC: 60 0.948070349604\n",
      "Overall AUC: 65 0.95230763774\n",
      "Overall AUC: 70 0.954357669604\n",
      "Overall AUC: 75 0.954380540339\n",
      "Overall AUC: 80 0.955462733107\n",
      "Overall AUC: 85 0.955485603842\n",
      "Overall AUC: 90 0.955485603842\n",
      "Overall AUC: 95 0.952837298757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classifier\n",
    "#clf = xgb.XGBClassifier(missing=np.nan, max_depth=5, n_estimators=350, learning_rate=0.03, nthread=4, subsample=0.95, colsample_bytree=0.85, seed=4242)\n",
    "\n",
    "\n",
    "#clf = OneClassSVM();\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=90)\n",
    "\n",
    "# fitting\n",
    "#clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "model.fit(X_train, y_train);\n",
    "y_eval_pred = model.predict(X_eval);\n",
    "print('Overall AUC:', i, roc_auc_score(y_eval,y_eval_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type                      Data/Info\n",
      "------------------------------------------------------------\n",
      "OneClassSVM              ABCMeta                   <class 'sklearn.svm.classes.OneClassSVM'>\n",
      "Pipeline                 type                      <class 'sklearn.pipeline.Pipeline'>\n",
      "RandomForestClassifier   ABCMeta                   <class 'sklearn.ensemble.<...>.RandomForestClassifier'>\n",
      "X_eval                   ndarray                   22806x306: 6978636 elems, type `float64`, 55829088 bytes (53.242767333984375 Mb)\n",
      "X_fit                    ndarray                   53214x306: 16283484 elems, type `float64`, 130267872 bytes (124.23312377929688 Mb)\n",
      "X_test                   ndarray                   75818x306: 23200308 elems, type `float64`, 185602464 bytes (177.00430297851562 Mb)\n",
      "X_train                  ndarray                   76020x306: 23262120 elems, type `float64`, 186096960 bytes (177.47589111328125 Mb)\n",
      "c                        Index                     Index(['ID', 'var3', 'var<...>ype='object', length=337)\n",
      "clf                      OneClassSVM               OneClassSVM(cache_size=20<...>01,\\n      verbose=False)\n",
      "col                      str                       TARGET\n",
      "df_test                  DataFrame                            ID  var3  var1<...>75818 rows x 307 columns]\n",
      "df_train                 DataFrame                            ID  var3  var1<...>76020 rows x 308 columns]\n",
      "division                 _Feature                  _Feature((2, 2, 0, 'alpha<...> 0, 0, 'alpha', 0), 8192)\n",
      "i                        int                       335\n",
      "id_test                  Series                    0             2\\n1       <...>7\\nName: ID, dtype: int64\n",
      "j                        int                       336\n",
      "len_test                 int                       75818\n",
      "len_train                int                       76020\n",
      "metrics                  module                    <module 'sklearn.metrics'<...>n\\\\metrics\\\\__init__.py'>\n",
      "model                    RandomForestClassifier    RandomForestClassifier(bo<...>        warm_start=False)\n",
      "np                       module                    <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pd                       module                    <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plt                      module                    <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "remove                   list                      n=29\n",
      "roc_auc_score            function                  <function roc_auc_score at 0x000000000A78BB70>\n",
      "submission               DataFrame                        ID  TARGET\\n0     <...>n\\n[999 rows x 2 columns]\n",
      "train_test_split         function                  <function train_test_split at 0x000000000A8A69D8>\n",
      "v                        ndarray                   76020: 76020 elems, type `float64`, 608160 bytes (593.90625 kb)\n",
      "y_eval                   ndarray                   22806: 22806 elems, type `int64`, 182448 bytes (178.171875 kb)\n",
      "y_eval_pred              ndarray                   22806: 22806 elems, type `int64`, 182448 bytes (178.171875 kb)\n",
      "y_fit                    ndarray                   53214: 53214 elems, type `int64`, 425712 bytes (415.734375 kb)\n",
      "y_pred                   ndarray                   999: 999 elems, type `float64`, 7992 bytes\n",
      "y_test_pred              ndarray                   999: 999 elems, type `int64`, 7992 bytes\n",
      "y_train                  ndarray                   76020: 76020 elems, type `int64`, 608160 bytes (593.90625 kb)\n"
     ]
    }
   ],
   "source": [
    "#%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878440366972\n",
      "0.998696219035\n",
      "0.934716290421\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.recall_score(y_eval, y_eval_pred, average='binary'))\n",
    "print(metrics.precision_score(y_eval, y_eval_pred, average='binary'))\n",
    "print(metrics.f1_score(y_eval, y_eval_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test);\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_test_pred})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print('Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
